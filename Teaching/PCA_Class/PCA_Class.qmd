---
title: "PCA_Class"
editor: source
freeze: auto
execute:
  warning: false
lang: fr
---

## Mathematical demonstration
Source : <https://medium.com/intuition/mathematical-understanding-of-principal-component-analysis-6c761004c2f8>

```{r}
#| include: false

library(tidyverse)
library(plotly)
library(knitr)
```

Considérons une matrice $x$ de taille $n \times p$ représentant $n$ individus et leurs $p$ paramètres associés :

```{r}
#| echo: false
#| label: tbl-values
#| tbl-cap: "Extrait de traits de 100 individus"

x <- rnorm(100, mean = 5, sd = .5)
y <- 2*x + rnorm(100)
data <- data.frame(x, y)
rm(x, y)

pretty_data <- data |> 
  mutate(Individus = row_number()) |> 
  rename("Trait 1" = x, "Trait 2" = y) |> 
  select(c(Individus, "Trait 1", "Trait 2"))

kable(head(pretty_data))
```

On peut également considérer qu'il s'agit de $n$ réalisations de $p$ variables aléatoires $X_{1}, \dots, X_{p}$.\
Ainsi, une ligne de $x$ correspond à un individu que l'on représente par le vecteur ligne $x_{i}$ avec ses $p$ paramètres :

$$
x_{i} = \begin{bmatrix} x_{1} \dots x_{p}\end{bmatrix}_{i} \text{ et } x_{i}^T = \begin{bmatrix}
      x_{1}\\
      \vdots \\
      x_{p}
    \end{bmatrix}_{i} \text{ sa transposée.}
$$
On peut représenter le jeu de données, la matrice $x$, par $n$ points dans un espace à $p$ dimensions comme dans notre exemple :

```{r}
#| echo: false
#| label: fig-traits
#| fig-cap: Biplot des deux traits d'intérêt

ggplot(data) + 
  geom_point(aes(x = x, y = y)) + 
  labs(x = "Trait 1", y = "Trait 2") +
  theme_minimal()
```

Pour faciliter les calculs, on centre et réduit les $X_{p}$ variables aléatoires :

```{r}
#| echo: false

data <- data |>
  mutate(
    scale_x = scale(x),
    scale_y = scale(y)
  )

angle <- data.frame(theta = round(seq.int(0, pi/2, length.out = 22)[-c(1, 22)], digits = 2))

data_anim <- cbind(data, "angle" = angle$theta[1])

for (i in 2:dim(angle)[1]) {
  data_anim <- rbind(data_anim, cbind(data, "angle" = angle$theta[i]))
}

data_anim <- data_anim |> 
  mutate(
    x_proj = (scale_x*cos(angle) + scale_y*sin(angle))*cos(angle),
    y_proj = (scale_x*cos(angle) + scale_y*sin(angle))*sin(angle)
  )
```

```{r}
#| echo: false

ggplot(data = data_anim) +
  geom_point(aes(x = scale_x, y = scale_y)) + 
  coord_fixed(ratio = 1) +
  theme_minimal()
```

On cherche à trouver un axe représenté par un vecteur $w$ de l'espace des paramètres, donc à $p$ dimensions, tel qu'il maximise la variance du jeu de données, ou nuage de point, projetée sur celui-ci.

C'est aussi équivalent à minimiser la somme du carré des résidus :

```{r}
#| echo: false

variance <- ggplot(data = data_anim) +
  geom_segment(
    aes(frame = angle, x = scale_x, xend = x_proj, y = scale_y, yend = y_proj),
    linetype = 2,
    colour   = "grey"
  ) +
  geom_abline(aes(frame = angle, slope = tan(angle), intercept = 0), colour = "grey") +
  geom_point(aes(frame = angle, x = scale_x, y = scale_y)) + 
  geom_point(aes(frame = angle, x = x_proj, y = y_proj), colour = "red") +
  coord_fixed(ratio = 1) +
  theme_minimal()

MSE <- ggplot(data = data_anim) +
  geom_segment(
    aes(frame = angle, x = scale_x, xend = x_proj, y = scale_y, yend = y_proj),
    linetype = 1,
    colour   = "red"
  ) +
  geom_abline(aes(frame = angle, slope = tan(angle), intercept = 0), colour = "grey") +
  geom_point(aes(frame = angle, x = x_proj, y = y_proj), colour = "grey") +
  geom_point(aes(frame = angle, x = scale_x, y = scale_y)) + 
  coord_fixed(ratio = 1) +
  theme_minimal()

subplot(ggplotly(variance), ggplotly(MSE))
```

Posons le problème mathématiquement :

![Projection de $x_{i}$ sur $w$](figures/angle.png)

Soit $x_{i}$ une composante de $x$ et $w$ un vecteur unitaire (donc $\|w\| = 1$ par définition). On a :

$$
\text{cos}(\theta) = \frac{x_{i} \cdot w}{\|x_{i}\|\|w\|}
$$

Tel que la projection orthogonale de $x_{i}$ sur $w$ est de norme :

$$
\|x_{i}\| \text{cos}(\theta) = \|x_{i}\|  \frac{x_{i} \cdot w}{\|x_{i}\|\|w\|} = x_{i} \cdot w
$$

On a donc le résidu associé :

\begin{align}

\| x_{i} - (x_{i} \cdot w)w \|^2 &= (x_{i} - (x_{i} \cdot w)w) \cdot  (x_{i} - (x_{i} \cdot w)w) \\
                                 &= \|x_{i}\|^2 - 2(w \cdot x_{i})^2 + (x_{i} \cdot w)^2w \cdot w \\
                                 &= x_{i} \cdot x_{i} - (w \cdot x_{i})^2

\end{align}

On a donc la somme des rédisus ou Mean Squared Error (MSE)

\begin{align}

\text{MSE}(w) &= \frac{1}{n} \sum_{i = 1}^n(\|x_{i}\|^2 - (w \cdot x_{i})^2) \\
&= \frac{1}{n} \sum_{i = 1}^n\|x_{i}\|^2 - \frac{1}{n} \sum_{i = 1}^n(w \cdot x_{i})^2 \\

\end{align}

On veut trouver $w$ tel que $\text{MSE}(w)$ soit minimale. Le premier terme est constant en fonction de $w$, il reste donc à maximiser le second terme (il y a un $-$ !). On remarque que le second terme peut s'écrire $\frac{1}{n} \sum_{i = 1}^n(w \cdot x_{i})^2 = E\left[(w \cdot x_{i})^2\right]$ or on a la relation $\text{Var}(X) = E[X^2] - E[X]^2$ d'où l'égalite :

\begin{align}

\frac{1}{n} \sum_{i = 1}^n(w \cdot x_{i})^2 &= (\frac{1}{n} \sum_{i = 1}^n w \cdot x_{i})^2 + \text{Var}(w \cdot x_{i}) \\
&= \text{Var}(w \cdot x_{i})

\end{align}

Car $w \cdot x_{i} = x_{i}$ puisque $w$ est unitaire et les $X_{p}$ sont centrées donc de moyennes nulles donc $\frac{1}{n} \sum_{i = 1}^n x_{i} = 0$.

Ainsi on a :

$$
\text{MSE}(w) = \frac{1}{n}\sum_{i = 1}^n \|x_{i}\|^2 - \text{Var}(w \cdot x_{i})
$$

Minimiser MSE revient donc à maximiser la variance des projections des $x_{i}$ mais comment faire ?

En rappelant :

$$
\text{Var}(x_{i}) = \frac{1}{p}x_{i}^Tx_{i} = \frac{1}{p} \sum_{j = 1}^px_{j, (i)}^2
$$

On obtient :

\begin{align}

\sigma_{w}^2 = \text{Var}(w \cdot x_{i}) &= \frac{1}{n} \sum_{i = 1}^n(w \cdot x_{i})^2 \\
&= \frac{1}{n}(xw)^T(xw) \\
&= \frac{1}{n}x^Tw^Txw \\
\sigma_{w}^2 &= w^Tcov_{X^T,X}w

\end{align}

avec $cov_{X^T,X}$ la matrice de variance-covariance des $X_{p}$ variables aléatoires correspondants à nos paramètres :
\begin{align}

cov_{X^T,X} = \text{Cov}\left[X^T,X\right] &= E\left[(X - \mu_{X^T})(X - \mu_{X})\right] \\
&= E\left[X^TX\right] \text{ en centrant les } X_{p}\\
\text{En développant :} \\
cov_{X^T,X} &= \begin{bmatrix} \text{Var}(X_{1}) & \dots & \text{Cov}(X_{1}, X_{p}) \\
                              \vdots & \ddots & \vdots \\
                              \text{Cov}(X_{p}, X_{1}) & \dots & \text{Var}(X_{p}) \end{bmatrix}

\end{align}

*N.B* : Attention à la dimensionnalité, $\frac{1}{n}xx^T = cov_{X^T,X}$ est une **matrice** de covariance de $X^T$ et $X$ (de dimension $n \times n$) alors que $\frac{1}{n}x^Tx = \frac{1}{n} \sum_{i = 1}^nx_{i}^2$ est un nombre (de dimension $1 \times 1$).

Ainsi, minimiser $\text{MSE}(w)$ revient à trouver $w$, vecteur unitaire, tel que $\sigma_{w}^2$ soit minimisé.\
Pour minimiser $\sigma_{w}^2$, on peut utiliser l'opérateur Lagrangien avec la contrainte que $w$ doit être un vecteur unitaire, c'est à dire que $\|w\| = w^Tw = 1$ comme suit :

\begin{align}

\mathcal{L}(w, \lambda) &\equiv \sigma_{w}^2 - \lambda(w^Tw - 1) \\
\frac{\partial\mathcal{L}}{\partial \lambda} &= (w^Tw - 1) \\
\frac{\partial\mathcal{L}}{\partial w} &= 2cov_{X^T,X}w - 2\lambda w

\end{align}

On résout le Lagrangien en posant les dérivées partielles nulles ce qui donne le système d'équations :

\begin{align}

w^Tw&= 1 \\
cov_{X^T,X}w &= \lambda w

\end{align}

Ce qui revient à trouver les valeurs et vecteurs propres de la matrice de covariance de X ! De plus le vecteur propre associé à la valeur propre la plus élevée maximisera la covariance.

## 3D Views

```{r}
library(FactoMineR)
```

```{r}
data("iris")
```

```{r}
iris |> plot_ly(
  x      = ~Sepal.Width,
  y      = ~Petal.Width,
  z      = ~Petal.Length,
  color  = ~Species,
  colors = c('#BF382A', '#0C4B8E', "green")
) |> 
  add_markers() |> 
  layout(
    scene = list(
      xaxis      = list(title = "Sepal Width"),
      yaxis      = list(title = "Petal Width"),
      zaxis      = list(title = "Petal Length"),
      aspectmode = 'data'
    )
  )
```

```{r}
iris |> 
  mutate(
    Sepal.Length = scale(Sepal.Length),
    Sepal.Width  = scale(Sepal.Width),
    Petal.Length = scale(Petal.Length),
    Petal.Width  = scale(Petal.Width)
    ) |> 
  plot_ly(
    x      = ~Sepal.Width,
    y      = ~Petal.Width,
    z      = ~Petal.Length,
    color  = ~Species,
    colors = c('#BF382A', '#0C4B8E', "green")
  ) |> 
  add_markers() |> 
  layout(
    scene = list(
      xaxis      = list(title = "Sepal Width"),
      yaxis      = list(title = "Petal Width"),
      zaxis      = list(title = "Petal Length"),
      aspectmode = 'data'
    )
  )
```

```{r}
iris |>
  select(-c(Sepal.Length, Species)) |> 
  PCA(graph = FALSE) |> 
  _$ind |> 
  _$coord |>
  as_tibble() |>
  mutate(Species = iris$Species) |> 
  plot_ly(
    x      = ~Dim.1,
    y      = ~Dim.2,
    z      = ~Dim.3,
    color  = ~Species,
    colors = c('#BF382A', '#0C4B8E', "green")
  ) |> 
  add_markers() |> 
  layout(
    scene = list(
      domain     = list(x = c(-3, 3), y = c(-3, 3), z = c(-3, 3)),
      xaxis      = list(title = "PC 1"),
      yaxis      = list(title = "PC 2"),
      zaxis      = list(title = "PC 3"),
      aspectmode = 'data'
    )
  )
```


## Results and interpretation

```{r}
library(factoextra)
```

```{r}
iris_pca <- iris |>
  select(-c(Species)) |>
  PCA(
    scale.unit = TRUE,
    ncp        = 5,
    graph      = FALSE
  )

iris_pca
```

```{r}
fviz_eig(iris_pca, addlabels = TRUE)
```

```{r}
fviz_pca_var(iris_pca, col.var = "black")
```

```{r}
iris_pca |> fviz_pca_var(
  col.var       = "cos2",
  gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
  repel         = TRUE # Avoid text overlapping
)
```

```{r}
library(corrplot)

var <- get_pca_var(iris_pca)
corrplot(var$cos2, is.corr = FALSE)
fviz_cos2(iris_pca, choice = "var", axes = 1:2)
fviz_contrib(iris_pca, choice = "var", axes = 1, top = 10)
fviz_contrib(iris_pca, choice = "var", axes = 2, top = 10)
```

```{r}
iris_pca |> fviz_pca_ind(
  axes       = c(1, 2),
  geom.ind   = "point",
  col.ind    = iris$Species, 
  palette    = c("#00AFBB", "#E7B800", "#FC4E07"),
  mean.point = FALSE
)

iris_pca |> fviz_pca_ind(
  axes       = c(2, 3),
  geom.ind   = "point",
  col.ind    = iris$Species, 
  palette    = c("#00AFBB", "#E7B800", "#FC4E07"),
  mean.point = FALSE
)

iris_pca |> fviz_pca_ind(
  axes       = c(3, 4),
  geom.ind   = "point",
  col.ind    = iris$Species, 
  palette    = c("#00AFBB", "#E7B800", "#FC4E07"),
  mean.point = FALSE
)
```

## Examples

## Related analyses
